{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 네이버 영화평 감성 분석 - TfidVectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../00.data/nsmc/train.tsv', sep='\\t')\n",
    "test_df = pd.read_csv('../00.data/nsmc/test.tsv', sep='\\t')"
   ]
  },
  {
   "source": [
    "### Tokenizer 함수 정의"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "def tw_tokenizer(text):\n",
    "    tokens_ko = okt.morphs(text)\n",
    "    return tokens_ko\n"
   ]
  },
  {
   "source": [
    "### TfidVectorizer 로 학습 / 변환"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tvecter = TfidfVectorizer(tokenizer=tw_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.9, min_df=3, ngram_range=(1, 2),\n",
       "                tokenizer=<function tw_tokenizer at 0x00000186458CE9D0>)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "tvecter.fit(train_df.document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tvect = tvecter.transform(train_df.document)\n",
    "X_test_tvect = tvecter.transform(test_df.document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.label.values\n",
    "y_test = test_df.label.values"
   ]
  },
  {
   "source": [
    "### LogisticRegression으로 학습/예측/평가"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(C=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8590672517603837"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "lr_clf.fit(X_train_tvect, y_train)\n",
    "pred = lr_clf.predict(X_test_tvect)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "source": [
    "### 실제 테스트"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1 = '진짜 개노잼이다.. 1편이랑 같은 감독맞나?러닝타임도 길어서 개지루함 ㄹㅇ'\n",
    "review2 = '이런 사랑영화가 다시 나올 수 있을까?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'진짜 개노잼이다 편이랑 같은 감독맞나러닝타임도 길어서 개지루함 ㄹㅇ'"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "import re\n",
    "review1 = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", review1)\n",
    "review1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을']\n",
    "morphs = okt.morphs(review1, stem=True) #토큰화\n",
    "review = ' '.join([word for word in morphs if not word in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tvect = tvecter.transform([review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr_clf.predict(review_tvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = ['진짜 개노잼이다.. 1편이랑 같은 감독맞나?러닝타임도 길어서 개지루함 ㄹㅇ', '이런 사랑영화가 다시 나올 수 있을까?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list = []\n",
    "for review in reviews:\n",
    "    review = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", review)\n",
    "    morphs = okt.morphs(review)\n",
    "    tmp = ' '.join([word for word in morphs if not word in stopwords])\n",
    "    review_list.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tvect = tvecter.transform(review_list)\n",
    "pred = lr_clf.predict(review_tvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "pred[0],pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfid_vect', TfidfVectorizer(tokenizer=tw_tokenizer)),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tfid_vect', TfidfVectorizer()), ('lr_clf', LogisticRegression())],\n",
       " 'verbose': False,\n",
       " 'tfid_vect': TfidfVectorizer(),\n",
       " 'lr_clf': LogisticRegression(),\n",
       " 'tfid_vect__analyzer': 'word',\n",
       " 'tfid_vect__binary': False,\n",
       " 'tfid_vect__decode_error': 'strict',\n",
       " 'tfid_vect__dtype': numpy.float64,\n",
       " 'tfid_vect__encoding': 'utf-8',\n",
       " 'tfid_vect__input': 'content',\n",
       " 'tfid_vect__lowercase': True,\n",
       " 'tfid_vect__max_df': 1.0,\n",
       " 'tfid_vect__max_features': None,\n",
       " 'tfid_vect__min_df': 1,\n",
       " 'tfid_vect__ngram_range': (1, 1),\n",
       " 'tfid_vect__norm': 'l2',\n",
       " 'tfid_vect__preprocessor': None,\n",
       " 'tfid_vect__smooth_idf': True,\n",
       " 'tfid_vect__stop_words': None,\n",
       " 'tfid_vect__strip_accents': None,\n",
       " 'tfid_vect__sublinear_tf': False,\n",
       " 'tfid_vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tfid_vect__tokenizer': None,\n",
       " 'tfid_vect__use_idf': True,\n",
       " 'tfid_vect__vocabulary': None,\n",
       " 'lr_clf__C': 1.0,\n",
       " 'lr_clf__class_weight': None,\n",
       " 'lr_clf__dual': False,\n",
       " 'lr_clf__fit_intercept': True,\n",
       " 'lr_clf__intercept_scaling': 1,\n",
       " 'lr_clf__l1_ratio': None,\n",
       " 'lr_clf__max_iter': 100,\n",
       " 'lr_clf__multi_class': 'auto',\n",
       " 'lr_clf__n_jobs': None,\n",
       " 'lr_clf__penalty': 'l2',\n",
       " 'lr_clf__random_state': None,\n",
       " 'lr_clf__solver': 'lbfgs',\n",
       " 'lr_clf__tol': 0.0001,\n",
       " 'lr_clf__verbose': 0,\n",
       " 'lr_clf__warm_start': False}"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "params ={\n",
    "    'tfid_vect__max_df': [30000],\n",
    "    'tfid_vect__min_df': [1],\n",
    "    'tfid_vect__ngram_range': [(1, 2), (1, 3)],\n",
    "    'lr_clf__C': [1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 51.0min finished\n",
      "{'lr_clf__C': 1, 'tfid_vect__max_df': 30000, 'tfid_vect__min_df': 1, 'tfid_vect__ngram_range': (1, 2)} 0.8448189531589742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_pipe = GridSearchCV(pipeline, param_grid= params, cv=3, scoring='accuracy', verbose=1)\n",
    "\n",
    "grid_pipe.fit(train_df.document, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TfidfVectorizer + LogisticRegression 정확도:0.8482\n"
     ]
    }
   ],
   "source": [
    "pred = grid_pipe.predict(test_df.document)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print (f'TfidfVectorizer + LogisticRegression 정확도:{acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}