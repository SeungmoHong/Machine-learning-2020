{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# IMDB 영화평 감정분석"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sentiment</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"5814_8\"</td>\n      <td>1</td>\n      <td>\"With all this stuff going down at the moment ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"2381_9\"</td>\n      <td>1</td>\n      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"7759_3\"</td>\n      <td>0</td>\n      <td>\"The film starts with a manager (Nicholas Bell...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('../00.data/IMDB/labeledTrainData.tsv', header=0, sep ='\\t', quoting=3)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 25000 entries, 0 to 24999\nData columns (total 3 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   id         25000 non-null  object\n 1   sentiment  25000 non-null  int64 \n 2   review     25000 non-null  object\ndtypes: int64(1), object(2)\nmemory usage: 586.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally sta'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.review[0][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# br태그를 공백으로 바꾸기\n",
    "df['review'] = df.review.str.replace('<br />', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 이외의 문자는 공백으로 변환\n",
    "import re\n",
    "\n",
    "df['review'] = df.review.apply(lambda x : re.sub('[^a-zA-Z]', ' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((17500, 1), (7500, 1))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_df = df.drop(['id', 'sentiment'], axis=1, inplace=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature_df, df.sentiment, test_size = 0.3, random_state=156\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "source": [
    "- CountVectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "count_vect.fit(X_train.review)\n",
    "X_train_count = count_vect.transform(X_train.review)\n",
    "X_test_count = count_vect.transform(X_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.886"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=10)\n",
    "lr_clf.fit(X_train_count, y_train)\n",
    "pred = lr_clf.predict(X_test_count)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "source": [
    "- TfidfVectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "tfidf_vect.fit(X_train.review)\n",
    "X_train_tfidf = tfidf_vect.transform(X_train.review)\n",
    "X_test_tfidf = tfidf_vect.transform(X_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8936"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=10)\n",
    "lr_clf.fit(X_train_tfidf, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "source": [
    "### 모델 저장하고 불러오기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model/imdb_lr.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(tfidf_vect, 'model/imdb_vect.pkl')\n",
    "joblib.dump(lr_clf, 'model/imdb_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지우기\n",
    "del tfidf_vect\n",
    "del lr_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vect = joblib.load('model/imdb_vect.pkl')\n",
    "new_lr = joblib.load('model/imdb_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test = new_vect.transform(X_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8936"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "pred = new_lr.predict(new_X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "source": [
    "### Pipeline을 써서 학습/예측/평가"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Count Vectorizer + Logistic Regression 정확도 : 0.8860\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count_vect', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('lr_clf', LogisticRegression(C=10))\n",
    "])\n",
    "pipeline.fit(X_train.review, y_train)\n",
    "pred = pipeline.predict(X_test.review)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'Count Vectorizer + Logistic Regression 정확도 : {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model/pipeline.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "joblib.dump(pipeline, 'model/pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipe = joblib.load('model/pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Count Vectorizer + Logistic Regression 정확도 : 0.8860\n"
     ]
    }
   ],
   "source": [
    "pred = new_pipe.predict(X_test.review)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'Count Vectorizer + Logistic Regression 정확도 : {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english')),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tfidf_vect', TfidfVectorizer(stop_words='english')),\n",
       "  ('lr_clf', LogisticRegression())],\n",
       " 'verbose': False,\n",
       " 'tfidf_vect': TfidfVectorizer(stop_words='english'),\n",
       " 'lr_clf': LogisticRegression(),\n",
       " 'tfidf_vect__analyzer': 'word',\n",
       " 'tfidf_vect__binary': False,\n",
       " 'tfidf_vect__decode_error': 'strict',\n",
       " 'tfidf_vect__dtype': numpy.float64,\n",
       " 'tfidf_vect__encoding': 'utf-8',\n",
       " 'tfidf_vect__input': 'content',\n",
       " 'tfidf_vect__lowercase': True,\n",
       " 'tfidf_vect__max_df': 1.0,\n",
       " 'tfidf_vect__max_features': None,\n",
       " 'tfidf_vect__min_df': 1,\n",
       " 'tfidf_vect__ngram_range': (1, 1),\n",
       " 'tfidf_vect__norm': 'l2',\n",
       " 'tfidf_vect__preprocessor': None,\n",
       " 'tfidf_vect__smooth_idf': True,\n",
       " 'tfidf_vect__stop_words': 'english',\n",
       " 'tfidf_vect__strip_accents': None,\n",
       " 'tfidf_vect__sublinear_tf': False,\n",
       " 'tfidf_vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tfidf_vect__tokenizer': None,\n",
       " 'tfidf_vect__use_idf': True,\n",
       " 'tfidf_vect__vocabulary': None,\n",
       " 'lr_clf__C': 1.0,\n",
       " 'lr_clf__class_weight': None,\n",
       " 'lr_clf__dual': False,\n",
       " 'lr_clf__fit_intercept': True,\n",
       " 'lr_clf__intercept_scaling': 1,\n",
       " 'lr_clf__l1_ratio': None,\n",
       " 'lr_clf__max_iter': 100,\n",
       " 'lr_clf__multi_class': 'auto',\n",
       " 'lr_clf__n_jobs': None,\n",
       " 'lr_clf__penalty': 'l2',\n",
       " 'lr_clf__random_state': None,\n",
       " 'lr_clf__solver': 'lbfgs',\n",
       " 'lr_clf__tol': 0.0001,\n",
       " 'lr_clf__verbose': 0,\n",
       " 'lr_clf__warm_start': False}"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "pipeline2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tfidf_vect__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "    'tfidf_vect__max_df'  : [300, 500, 700],\n",
    "    'lr_clf__C': [1, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed: 13.0min finished\n",
      "{'lr_clf__C': 10, 'tfidf_vect__max_df': 700, 'tfidf_vect__ngram_range': (1, 2)} 0.8822287469759523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_pipe = GridSearchCV(pipeline2, param_grid= params, cv=3, scoring='accuracy', verbose=1)\n",
    "\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8873333333333333"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "pred = grid_pipe.predict(X_test.review)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tfidf_vect__ngram_range' : [(1,2), (1,3)],\n",
    "    'tfidf_vect__max_df'  : [600,700,800],\n",
    "    'lr_clf__C': [9, 10, 11]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed: 22.3min finished\n",
      "{'lr_clf__C': 9, 'tfidf_vect__max_df': 800, 'tfidf_vect__ngram_range': (1, 2)} 0.8856573184269131\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline2, param_grid= params, cv=3, scoring='accuracy', verbose=1)\n",
    "\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8869333333333334"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "pred = grid_pipe.predict(X_test.review)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tfidf_vect__ngram_range' : [(1,2)],\n",
    "    'tfidf_vect__max_df'  : [750,800,850],\n",
    "    'lr_clf__C': [7, 8, 9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  6.3min finished\n",
      "{'lr_clf__C': 8, 'tfidf_vect__max_df': 800, 'tfidf_vect__ngram_range': (1, 2)} 0.8857144645495487\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline2, param_grid= params, cv=3, scoring='accuracy', verbose=1)\n",
    "\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8864"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "pred = grid_pipe.predict(X_test.review)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tfidf_vect__ngram_range' : [(1,2)],\n",
    "    'tfidf_vect__max_df'  : [800],\n",
    "    'lr_clf__C': [8],\n",
    "    'tfidf_vect__min_df': [1,2,3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.3min finished\n",
      "{'lr_clf__C': 8, 'tfidf_vect__max_df': 800, 'tfidf_vect__min_df': 2, 'tfidf_vect__ngram_range': (1, 2)} 0.8862287600625516\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline2, param_grid= params, cv=3, scoring='accuracy', verbose=1)\n",
    "\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8918666666666667"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "pred = grid_pipe.predict(X_test.review)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tfidf_vect__ngram_range' : [(1,2)],\n",
    "    'tfidf_vect__max_df'  : [800, 900, 1000],\n",
    "    'lr_clf__C': [8,10,20,30],\n",
    "    'tfidf_vect__min_df': [2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  3.9min finished\n",
      "{'lr_clf__C': 30, 'tfidf_vect__max_df': 900, 'tfidf_vect__min_df': 2, 'tfidf_vect__ngram_range': (1, 2)} 0.887543022929583\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline2, param_grid= params, cv=3, scoring='accuracy', verbose=1)\n",
    "\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8925333333333333"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "pred = grid_pipe.predict(X_test.review)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}